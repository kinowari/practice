{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MRuSrP7JQ00i",
        "1b95Z8u7Q3OL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinowari/practice/blob/main/pract2/mirea_2_seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Разбор практики 1.**"
      ],
      "metadata": {
        "id": "RQ8rTFmQ0ueR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."
      ],
      "metadata": {
        "id": "9P9bWaC9QQJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(1, 1, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "Hh8sSJkEWNmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "r9HoH1koVQXi",
        "outputId": "e3020bb5-04c1-45cf-937a-77d6c2337325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.9774]], requires_grad=True), Parameter containing:\n",
              " tensor([0.1165], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[-1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([1.0])\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "MLmGhtWFTYlV",
        "outputId": "9ca8cb0a-4683-44d6-e910-69e6908a587c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-1.]], requires_grad=True), Parameter containing:\n",
              " tensor([1.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "UFr5InkDTf-r",
        "outputId": "6504e778-9bd4-4c5f-c2f8-67d22bb522d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "sXJqgPEwAwHa",
        "outputId": "12c3a893-da2c-4b19-de63-0a803b132b38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 3**. Cделать нейрон, соответствующий оператору И."
      ],
      "metadata": {
        "id": "TRxJxcRJQsMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "7dvDtA7HX3V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "olMqAnQtX5NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b3ffe4-f637-4338-a46f-9db503a316ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.4475]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.0402], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([-1.5])\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "kAtwMX7HQ0aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bb0196-ecaf-489c-858e-c3d420d454aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[1., 1.]], requires_grad=True), Parameter containing:\n",
              " tensor([-1.5000], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "P27EdNkrXloh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96718328-9f63-41df-8077-3791a2d6b905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 0.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "c04b6405-d7ae-4e49-a6c1-6f478572f17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BJc_ipGrei3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "2788282c-a684-43c1-f219-3d16f45f14d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjVTdBf-rei5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "9b335917-e009-479c-e75d-9d1565422b8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyomxCJUrei5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."
      ],
      "metadata": {
        "id": "MRuSrP7JQ00i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1., 1.]])\n",
        "neuron.fc.bias.data = torch.tensor([-0.5])"
      ],
      "metadata": {
        "id": "23RuhFqbQ24-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "i-BZHFqnXpLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7105825d-66f2-48db-a250-8a3bfe6be45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 0.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "8181961c-7669-4a37-c4ce-1277622af170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZuFtRlvyixQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "26449834-8084-4c6a-a696-141449d0622f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyu88Kg0yixR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "0100e5f4-c3a6-4188-9c5b-42cf823eb1e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2OhYEC7yixS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."
      ],
      "metadata": {
        "id": "1b95Z8u7Q3OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ],
      "metadata": {
        "id": "hWP7ee7tjCGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "HgDrZ7PBjGwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Занятие 2.**"
      ],
      "metadata": {
        "id": "zjM7DFps2rBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"
      ],
      "metadata": {
        "id": "KlS1ciOPBg7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n",
        "\n",
        "[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n",
        "\n",
        "[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n",
        "\n",
        "[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"
      ],
      "metadata": {
        "id": "kP06X1SrzLlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "alR-VHX_gnQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_params(*tensors):\n",
        "  for x in tensors:\n",
        "    print('---')\n",
        "    print(f\"data - {x.data}\")\n",
        "    print(f\"grad - {x.grad}\")\n",
        "    print(f\"grad_fn - {x.grad_fn}\")\n",
        "    print(f\"req_grad - {x.requires_grad}\")\n",
        "    print(f\"is_leaf - {x.is_leaf}\")"
      ],
      "metadata": {
        "id": "ipOjjh8OCk4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(5.0)\n",
        "show_tensor_params(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXas0qEnybl9",
        "outputId": "4385d7e1-bc39-4647-8f40-559c403f8ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 5.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n",
        "\n",
        "For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n",
        "\n",
        "Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"
      ],
      "metadata": {
        "id": "NuymHxbjzDfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Slide A4\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0)\n",
        "c = a*b\n",
        "\n",
        "c.backward()\n",
        "# (2 * c).backward()"
      ],
      "metadata": {
        "id": "O5NE4zRPyqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(a, b, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-TbdvmH-oaM",
        "outputId": "67a03e27-8396-419a-fe3f-4b530dabfec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 3.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - None\n",
            "grad_fn - <MulBackward0 object at 0x7f2d51775b90>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Slide Simple5"
      ],
      "metadata": {
        "id": "NqUcFO2rCXni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "\n",
        "c.retain_grad()\n",
        "e.retain_grad()\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "gYTsuKc3Fn8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(a, b, c, d, e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egTBJvIBF5EO",
        "outputId": "3d1429c0-b930-49e6-c24d-268dfb6d7460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 12.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - 8.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - 4.0\n",
            "grad_fn - <MulBackward0 object at 0x7f2d51766790>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 4.0\n",
            "grad - 6.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 24.0\n",
            "grad - 1.0\n",
            "grad_fn - <MulBackward0 object at 0x7f2d51770110>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In place 1\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "W5Cs2_REGgOS",
        "outputId": "1f6d02d7-001f-4974-8528-3175f60a6081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3de2fcb7bcd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WeqfWzYGhKG",
        "outputId": "62245ba0-49c5-4703-999f-b6a81a5a5839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In place 2\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c+d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "iLZ3Z4qIH4J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ySSjlRUIH0e",
        "outputId": "36d5594c-d9f2-4b41-ea60-84dc03e55053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# отвязка от графа\n",
        "k = e.detach()"
      ],
      "metadata": {
        "id": "4jbSqPGkILEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.storage == e.storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLKUQ08AJhZT",
        "outputId": "9c7c338a-a5b7-44ca-d396-44e7fca170a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(e, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqo-PW2kJkaG",
        "outputId": "d82e5cb3-e0e3-4a13-ae39-b16c55111648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - <AddBackward0 object at 0x7f2d51766510>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание собственной библиотеки автоматического дифференцирования"
      ],
      "metadata": {
        "id": "B8urvcsAKi62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "txwYkEHMftme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Простой пример"
      ],
      "metadata": {
        "id": "urGQXw9GgdQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3*x**2 - 4*x + 5"
      ],
      "metadata": {
        "id": "bPNsEPbZfwXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(3.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKMjYubGfzo5",
        "outputId": "251797af-dea0-4cac-9617-4ea625e46f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.arange(-5, 5, 0.25)\n",
        "ys = f(xs)\n",
        "plt.plot(xs, ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2Mufja5Mf2dD",
        "outputId": "ef31f0a0-2f59-44a2-deab-6c6653138789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2d5173c4d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 0.000001\n",
        "x = 2\n",
        "(f(x + h) - f(x))/h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzRAdjhFgGo8",
        "outputId": "3867db0e-6068-470a-bab3-caf547a621f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.000003001384925"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Более сложный пример"
      ],
      "metadata": {
        "id": "dOszwXaTgkd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "d = a*b + c\n",
        "print(d)"
      ],
      "metadata": {
        "id": "BOzPl8NWghve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1b642f-8361-4f35-a8fc-15a806050d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 0.0001\n",
        "\n",
        "# inputs\n",
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "\n",
        "d1 = a*b + c\n",
        "c += h\n",
        "d2 = a*b + c\n",
        "\n",
        "print('d1', d1)\n",
        "print('d2', d2)\n",
        "print('slope', (d2 - d1)/h)"
      ],
      "metadata": {
        "id": "P9Xx4_omgrkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12af0302-51e9-433e-ebca-cca81b6d860f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d1 4.0\n",
            "d2 4.0001\n",
            "slope 0.9999999999976694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wle8vv7_grKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"
      ],
      "metadata": {
        "id": "dlDJrMMsOgNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function"
      ],
      "metadata": {
        "id": "sPyPkdq5RH94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Exp(Function):\n",
        "  \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, i):\n",
        "    \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "    \"\"\"\n",
        "    result = i.exp()\n",
        "    ctx.save_for_backward(result)\n",
        "    return result\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "    \"\"\"\n",
        "    print(ctx.saved_tensors)\n",
        "    result, = ctx.saved_tensors\n",
        "    return grad_output * result"
      ],
      "metadata": {
        "id": "F5-hnsEiPIz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use it by calling the apply method\n",
        "input = torch.tensor(2.0, requires_grad=True)\n",
        "output = Exp.apply(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elaOA8bdRiMc",
        "outputId": "5227a995-2020-4242-d479-bacf8eddff33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.3891, grad_fn=<ExpBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.exp(2.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlcZLt-RSGgG",
        "outputId": "676d6f78-d254-4cfb-c3c5-1a8e5a1c8826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.38905609893065"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.backward()\n",
        "show_tensor_params(output)\n",
        "show_tensor_params(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om6dn414SQeA",
        "outputId": "fe644e9d-debd-489e-de24-e287bda96f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
            "---\n",
            "data - 7.389056205749512\n",
            "grad - None\n",
            "grad_fn - <torch.autograd.function.ExpBackward object at 0x7f2d47309e50>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 2.0\n",
            "grad - 7.389056205749512\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"
      ],
      "metadata": {
        "id": "d_14IqfeSnLM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-tos81Ci-50u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Polynomial(torch.autograd.Function):\n",
        "\n",
        "    def __init__(self, ctx):\n",
        "      self.ctx = ctx\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "\n",
        "        input, = ctx.saved_tensors\n",
        "        return (7.5 * input ** 2 - 1.5) * grad_output"
      ],
      "metadata": {
        "id": "iNC-MA-m-53z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HcHrSZw-56v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Polynomial(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        return (7.5 * input ** 2 - 1.5) * grad_output"
      ],
      "metadata": {
        "id": "i5cNegVYOd8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0KOwwOZF6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwDl2sFqF66y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class test:\n",
        "  pass\n",
        "\n",
        "  def __add__(self, other):\n",
        "    return None\n",
        "\n",
        "test + test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "AmW9IEuLF7A5",
        "outputId": "de375a70-c8c4-4e83-948f-2982ea7f1653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-43d7c7d328ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'type' and 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать"
      ],
      "metadata": {
        "id": "fA2PNhudUNij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "72kkrG60v2E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Value:\n",
        "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
        "\n",
        "    def __init__(self, data, _children=(), _op=''):\n",
        "        self.data = data\n",
        "        self.grad = 0\n",
        "        # internal variables used for autograd graph construction\n",
        "        self._backward = lambda: None # function \n",
        "        self._prev = set(_children) # set of Value objects\n",
        "        self._op = _op # the op that produced this node, string ('+', '-', ....)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(self.data+other.data, (self, other), '+')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad\n",
        "            other.grad += out.grad\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(self.data*other.data, (self, other), '*')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other.data * out.grad\n",
        "            other.grad += self.data * out.grad\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
        "        out = Value(self.data**other, (self,), '**' + str(other))\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other*self.data**(other-1)* out.grad\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def relu(self):\n",
        "        out = Value(np.maximum(0, self.data), (self,), 'ReLU')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad if out.data > 0 else 0\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self):\n",
        "\n",
        "        # topological order all of the children in the graph\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "        build_topo(self)\n",
        "\n",
        "        # go one variable at a time and apply the chain rule to get its gradient\n",
        "        self.grad = 1\n",
        "        for v in reversed(topo):\n",
        "            v._backward()\n",
        "\n",
        "    def __neg__(self): # -self\n",
        "        return self * -1\n",
        "\n",
        "    def __radd__(self, other): # other + self\n",
        "        return self + other\n",
        "\n",
        "    def __sub__(self, other): # self - other\n",
        "        return self + (-other)\n",
        "\n",
        "    def __rsub__(self, other): # other - self\n",
        "        return other + (-self)\n",
        "\n",
        "    def __rmul__(self, other): # other * self\n",
        "        return self * other\n",
        "\n",
        "    def __truediv__(self, other): # self / other\n",
        "        return self * other**-1\n",
        "\n",
        "    def __rtruediv__(self, other): # other / self\n",
        "        return other * self**-1\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Value(data={self.data}, grad={self.grad})\""
      ],
      "metadata": {
        "id": "chDdD9oSUlUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sanity_check():\n",
        "\n",
        "    x = Value(-4.0)\n",
        "    z = 2 * x + 2 + x\n",
        "  \n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xmg, ymg = x, y\n",
        "\n",
        "    x = torch.Tensor([-4.0]).double()\n",
        "    x.requires_grad = True\n",
        "    z = 2 * x + 2 + x\n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xpt, ypt = x, y\n",
        "\n",
        "    \n",
        "    # forward pass went well\n",
        "    assert ymg.data == ypt.data.item()\n",
        "    # backward pass went well\n",
        "    print(xmg, xpt, xpt.grad)\n",
        "    assert xmg.grad == xpt.grad.item()\n",
        "\n",
        "\n",
        "def test_more_ops():\n",
        "\n",
        "    a = Value(-4.0)\n",
        "    b = Value(2.0)\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c += c + 1\n",
        "    c += 1 + c + (-a)\n",
        "    d += d * 2 + (b + a).relu()\n",
        "    d += 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g += 10.0 / f\n",
        "    g.backward()\n",
        "    amg, bmg, gmg = a, b, g\n",
        "\n",
        "    a = torch.Tensor([-4.0]).double()\n",
        "    b = torch.Tensor([2.0]).double()\n",
        "    a.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c = c + c + 1\n",
        "    c = c + 1 + c + (-a)\n",
        "    d = d + d * 2 + (b + a).relu()\n",
        "    d = d + 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g = g + 10.0 / f\n",
        "    g.backward()\n",
        "    apt, bpt, gpt = a, b, g\n",
        "\n",
        "    tol = 1e-6\n",
        "    # forward pass went well\n",
        "    assert abs(gmg.data - gpt.data.item()) < tol\n",
        "    # backward pass went well\n",
        "    assert abs(amg.grad - apt.grad.item()) < tol\n",
        "    assert abs(bmg.grad - bpt.grad.item()) < tol"
      ],
      "metadata": {
        "id": "vY7OzWjuUiaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Value(-4.0)\n",
        "b = Value(2.0)\n",
        "d = Value(3.0)"
      ],
      "metadata": {
        "id": "1LgTiYeZ-WGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = a + b\n",
        "e = c * d\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "Y0svSAs2h0Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sanity_check()"
      ],
      "metadata": {
        "id": "w9n8DN6RYkrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ee8148-e539-4725-c6f1-ffb30b9f316c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_more_ops()"
      ],
      "metadata": {
        "id": "1T198QDQYh_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение на основе собственной бибилотеки"
      ],
      "metadata": {
        "id": "o-KbDOhMYHZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Многослойный перцептрон на основе класса Value"
      ],
      "metadata": {
        "id": "uVK1JLXom0Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Module:\n",
        "\n",
        "    def zero_grad(self):\n",
        "        ...\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "class Neuron(Module):\n",
        "\n",
        "    def __init__(self, nin, nonlin=True):\n",
        "        self.w = ...\n",
        "        self.b = ...\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "    def __call__(self, x):\n",
        "        act = ...\n",
        "        return ...\n",
        "\n",
        "    def parameters(self):\n",
        "        return ...\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
        "\n",
        "class Layer(Module):\n",
        "\n",
        "    def __init__(self, nin, nout, **kwargs):\n",
        "        self.neurons = ...\n",
        "\n",
        "    def __call__(self, x):\n",
        "        out = ...\n",
        "        return out[0] if len(out) == 1 else out\n",
        "\n",
        "    def parameters(self):\n",
        "        return ...\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
        "\n",
        "class MLP(Module):\n",
        "\n",
        "    def __init__(self, nin, nouts):\n",
        "        sz = ...\n",
        "        self.layers = [Layer(sz[i], sz[i+1], nonlin=(i!=len(nouts)-1)) for i in range(len(nouts))]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        ...\n",
        "        return x\n",
        "\n",
        "    def parameters(self):\n",
        "        return ...\n",
        "\n",
        "    def __repr__(self):\n",
        "        repr = '\\n'.join(str(layer) for layer in self.layers)\n",
        "        return f\"MLP of [{repr}]\""
      ],
      "metadata": {
        "id": "rkl70dxhkcQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение многослойного перцептрона"
      ],
      "metadata": {
        "id": "YkkaE1V1m5i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам перцептрон"
      ],
      "metadata": {
        "id": "WWy-H8eCn2zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = MLP(3, [4, 4, 1])\n",
        "print(model)\n",
        "print(\"number of parameters\", len(model.parameters()))"
      ],
      "metadata": {
        "id": "3La6nRi4m920"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набор данных"
      ],
      "metadata": {
        "id": "OvkZVOLcnvqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = [\n",
        "  [2.0, 3.0, -1.0],\n",
        "  [3.0, -1.0, 0.5],\n",
        "  [0.5, 1.0, 1.0],\n",
        "  [1.0, 1.0, -1.0],\n",
        "]\n",
        "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
      ],
      "metadata": {
        "id": "aLJULsNanpVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(20):\n",
        "\n",
        "    # forward\n",
        "    ...\n",
        "\n",
        "    # calculate loss (mean square error)\n",
        "    ...\n",
        "    \n",
        "    # backward (zero_grad + backward)\n",
        "    ...\n",
        "    \n",
        "    # update\n",
        "    learning_rate = ...\n",
        "    for p in n.parameters():\n",
        "        ...\n",
        "    \n",
        "    if k % 1 == 0:\n",
        "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"
      ],
      "metadata": {
        "id": "OuCTaTB8n5l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание"
      ],
      "metadata": {
        "id": "n4maaWL5yg-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`"
      ],
      "metadata": {
        "id": "2yyK39RYo084"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n",
        "[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)"
      ],
      "metadata": {
        "id": "FdzPyQ-hylKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код"
      ],
      "metadata": {
        "id": "bGMpj9Pf61n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2"
      ],
      "metadata": {
        "id": "3VPpRO6H6SHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код"
      ],
      "metadata": {
        "id": "2YJfxtqSphFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно."
      ],
      "metadata": {
        "id": "nRRgw0HNsr_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/guides/integrations/pytorch"
      ],
      "metadata": {
        "id": "W5AWW52REfn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/ref/python/watch  "
      ],
      "metadata": {
        "id": "ekFfy3cWVOIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/guides/track/jupyter"
      ],
      "metadata": {
        "id": "9G4SOp28ok0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "lumiR8oykL04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Xw3c6P7BkP9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "run = wandb.init(project=\"polynom_learning_\")"
      ],
      "metadata": {
        "id": "udPv0ufwkxOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "Xtpc9MAUodNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}